artifact_path: model # This specifies the relative path where the model artifacts (e.g., model.pkl) are stored.
flavors: # Flavors define different ways to load and serve the model
  python_function: # This is a generic way to load the model, making it usable across various MLflow-compatible tools
    env:
      conda: conda.yaml # The Conda environment file for dependencies.
      virtualenv: python_env.yaml # The Virtualenv configuration file.
    loader_module: mlflow.sklearn # Specifies that this model should be loaded using mlflow.sklearn
    model_path: model.pkl # The actual model file (in this case, model.pkl) is stored in the model/ directory
    predict_fn: predict # The function used for making predictions. Default is predict
    python_version: 3.10.6 # The Python version used when the model was logged.
  sklearn:
    code: null # means no additional source code files were saved
                # for example
                # custom_code/
                # model/
                #  │── MLmodel
                #  │── model.pkl
                #  │── conda.yaml
                #  │── custom_code/
                #  │   ├── preprocessing.py
                #  │   ├── utils.py
    pickled_model: model.pkl # Specifies that the model was serialized using Pickle and saved as model.pkl.
    serialization_format: cloudpickle 
    # Indicates that CloudPickle was used for serialization (which supports a wider range of objects than standard Pickle).
    sklearn_version: 1.1.3 # The version of Scikit-Learn used when training the model.
mlflow_version: 2.0.1 # Specifies the version of MLflow used when logging the model.
model_uuid: df3d9746976e448592bce94d245f5d18 
# A unique identifier assigned to the model for tracking purposes.
run_id: 0f83eab2ce0c4866959d66d5828e413a 
# The MLflow run ID associated with this model.This ID helps track the exact run that produced it.
saved_input_example_info: # This section stores an example input for inference.
  artifact_path: input_example.json # The saved input example is stored as input_example.json.
  format: tf-serving # Specifies the format of the saved input example (here, it's in TensorFlow Serving format).
  type: ndarray # Specifies that the input data is an ndarray (NumPy array).
signature: # Defines the expected input and output formats for the model.
  inputs: '[{"type": "tensor", "tensor-spec": {"dtype": "float64", "shape": [-1, 4]}}]'
          # The model expects a tensor with shape [-1, 4], meaning:
          # -1 → Variable batch size.
          # 4 → Each input has 4 features.
          # The data type is float64.
  outputs: '[{"type": "tensor", "tensor-spec": {"dtype": "int64", "shape": [-1]}}]'
  # The output is a tensor of int64 values with a variable batch size (-1).
utc_time_created: '2025-02-01 04:56:40.384177' # The exact timestamp (UTC) when the model was saved.
